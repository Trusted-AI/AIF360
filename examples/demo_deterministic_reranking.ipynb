{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the capabilities of the DeterministicReranking algorithm.\n",
    "The algorithm provides a way to construct balanced rankings of candidates based on precalculated scores.\n",
    "\n",
    "*Based on: [Sahin Cem Geyik, Stuart Ambler, & Krishnaram Kenthapadi (2019). Fairness-Aware Ranking in Search & Recommendation Systems with Application to LinkedIn Talent Search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining](https://doi.org/10.48550/arXiv.1905.01989).*\n",
    "\n",
    "The notebook is organized as follows:\n",
    "1. Introduction;\n",
    "2. A toy example;\n",
    "3. Application to the LawSchoolGPA dataset;\n",
    "4. Theoretical background."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking algorithms are at the core of search and recommendation systems used in, among others, hiring, college admissions, and web-searches. It is clear that algorithmic bias in such cases can create or amplify unacceptable discrimination based on race, gender, or other attributes. Thus, a way of constructing \"fair\" rankings is needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms presented here take as input a **dataset that has already been ranked** (scored), possibly by some other machine learning model, and order them in a way that satisfies specified **fairness requirements**, expressed in a form of a **distribution over the protected attributes**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. A toy example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a collection of 10 balls: 5 red and 5 blue. We assign each of them a score from 0 to 100; however, for some reason the red balls have a higher average score than the blue ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red mean score: 73.0\n",
      "Blue mean score: 50.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "balls = pd.DataFrame([['r', 100],['r', 90],['r', 85],['r', 70],['b', 70],['b', 60],['b', 50],['b', 40],['b', 30],['r', 20]],\n",
    "                     columns=['color', 'score'])\n",
    "\n",
    "print(f\"Red mean score: {np.mean(balls[balls['color'] == 'r']['score'])}\")\n",
    "print(f\"Blue mean score: {np.mean(balls[balls['color'] == 'b']['score'])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, say we want to take the 6 best balls based on their score. In real life, the need for this limited \"sub-ranking\" may arise for many reasons. For example, the landing page of our ball-selling website may only have space for 6 items. \n",
    "\n",
    "This is similar to the case presented in the original paper, where the algorithm is used to rank job-seekers for recruiters on LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  color  score\n",
       "0     r    100\n",
       "1     r     90\n",
       "2     r     85\n",
       "3     r     70\n",
       "4     b     70\n",
       "5     b     60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls.sort_values(by='score', ascending=False)[:6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we notice that we have only 1 blue ball in this ranking, and it is in the last position! On one hand, it seems fair in terms of scores. However, we may want a more **equal representation** of different colors in the ranking. The possible motivations for that in real life are clear.\n",
    "\n",
    "In our case, the color is the **protected attribute**, and the red balls are a **privileged class**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may get a fairer ranking using the `DeterministicReranking` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "c:\\Users\\andre\\miniconda3\\envs\\aif\\lib\\site-packages\\torch\\_functorch\\deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import RegressionDataset\n",
    "from aif360.algorithms.postprocessing.deterministic_reranking import DeterministicReranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a RegressionDataset with color as the protected attribute and red as the privileged class.\n",
    "balls_ds = RegressionDataset(df=balls, dep_var_name='score', protected_attribute_names=['color'], privileged_classes=[['r']])\n",
    "# keep the un-normalized scores for clarity; RegressionDataset normalizes them to be from 0 to 1.\n",
    "balls_ds.labels = np.transpose([balls['score']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the DeterministicReranking class, we need to pass the **protected attribute values** of the priviliged and unprivileged groups.\n",
    "We do that using a list of dictionaries for each group, with the **name of the attribute as the key**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RegressionDataset class automatically maps the priviliged attribute value (color='red') to 1 and the other to 0.\n",
    "dr = DeterministicReranking(unprivileged_groups=[{'color': 0}], privileged_groups=[{'color': 1}])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `fit_predict` method to get the ranking. The arguments are:\n",
    "- `dataset` is the dataset to construct a ranking from;\n",
    "- `rec_size` is the **size** of the ranking we need - in our case 6;\n",
    "- `target_prop` is the **desired proportion** of items of each group in the ranking in the form of dictionary; the keys are the corresponding protected attribute values. We need equal representation, so we pass `{0: 0.5, 1: 0.5}`;\n",
    "- `rerank_type` is the algorithm to use; for further details, skip to section 4 of this notebook. For now, we stick to the default `Constrained`;\n",
    "- `renormalize_scores` will normalize the scores in the result so that the lowest is 0 and the highest is 1. Default is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  score\n",
       "0    1.0  100.0\n",
       "1    1.0   90.0\n",
       "4    0.0   70.0\n",
       "2    1.0   85.0\n",
       "5    0.0   60.0\n",
       "6    0.0   50.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_ranking = dr.fit_predict(dataset=balls_ds, rec_size=6, target_prop=[0.5, 0.5])\n",
    "fair_ranking.convert_to_dataframe()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this result, the proportions are equal. Additionally, as the algorithm goes through positions in the ranking one-by-one, checking each time for violations of fairness, the items belonging to the unprivileged group (blue balls) **aren't all at the \"bottom\"** of the ranking."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Application to the Law School GPA Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the algorithm to a more serious example - the Law School GPA dataset.\n",
    "\n",
    "The aim is to obtain a ranking of size 20 according to the value in `zfygpa` with fairness constraints on `race`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    response = requests.get(\"http://www.seaphe.org/databases/LSAC/LSAC_SAS.zip\")\n",
    "    temp_file_name = os.path.join(temp_dir, \"LSAC_SAS.zip\")\n",
    "    with open(temp_file_name, \"wb\") as temp_file:\n",
    "        temp_file.write(response.content)\n",
    "    with zipfile.ZipFile(temp_file_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "    data = pd.read_sas(os.path.join(temp_dir, \"lsac.sas7bdat\"))\n",
    "    data = data.assign(gender=(data[\"gender\"] == b\"male\") * 1)\n",
    "    data['race'] = data['race1']\n",
    "    data = data[['race', 'gender', 'lsat', 'ugpa', 'zfygpa']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 2495 rows removed from RegressionDataset.\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import RegressionDataset\n",
    "dataset = RegressionDataset(data, dep_var_name='zfygpa', protected_attribute_names=['race'], privileged_classes=[[b'white']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a ranking strictly according to the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset.convert_to_dataframe()[0].sort_values(by=['zfygpa'], ascending=False)\n",
    "unfair_ranking = RegressionDataset(df=dataset_df, dep_var_name='zfygpa', protected_attribute_names=['race'], privileged_classes=[[1]])\n",
    "# Again, for clarity we leave the labels (scores) unnormalized.\n",
    "unfair_ranking.labels = np.transpose([dataset_df['zfygpa']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: **all the items in the top-20 come from the priviliged group!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25381</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.970960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.960859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.948232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16978</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.924242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.924242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20773</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16428</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17585</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.912879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11738</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.911616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  gender      lsat   ugpa    zfygpa\n",
       "5537    1.0     1.0  0.716216  1.000  1.000000\n",
       "25381   1.0     1.0  0.675676  0.750  0.970960\n",
       "9699    1.0     1.0  0.891892  1.000  0.960859\n",
       "6160    1.0     1.0  0.783784  0.750  0.953283\n",
       "13478   1.0     1.0  0.783784  0.700  0.953283\n",
       "21127   1.0     0.0  0.837838  0.875  0.952020\n",
       "19475   1.0     0.0  0.891892  0.950  0.948232\n",
       "24329   1.0     1.0  0.729730  0.525  0.944444\n",
       "11152   1.0     1.0  1.000000  0.975  0.944444\n",
       "16978   1.0     0.0  0.675676  1.000  0.930556\n",
       "7525    1.0     1.0  0.864865  0.850  0.924242\n",
       "48      1.0     0.0  0.756757  1.000  0.924242\n",
       "1600    1.0     0.0  0.891892  1.000  0.920455\n",
       "20773   1.0     1.0  0.972973  0.750  0.920455\n",
       "22047   1.0     1.0  1.000000  0.850  0.920455\n",
       "16428   1.0     1.0  0.756757  0.875  0.920455\n",
       "17585   1.0     1.0  0.702703  0.600  0.916667\n",
       "8119    1.0     0.0  0.594595  0.700  0.912879\n",
       "11738   1.0     1.0  0.729730  0.875  0.911616\n",
       "10563   1.0     1.0  1.000000  0.900  0.909091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = unfair_ranking.convert_to_dataframe()[0][:20]\n",
    "rank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get a fair ranking using `DeterministicReranking`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25381</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.970960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20893</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.900253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9699</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.887626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21127</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.952020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26383</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.864899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.948232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.856061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.853535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.849747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16978</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17964</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.849747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  gender      lsat      ugpa    zfygpa\n",
       "5537    1.0     1.0  0.637931  1.000000  1.000000\n",
       "25381   1.0     1.0  0.586207  0.473684  0.970960\n",
       "20893   0.0     0.0  0.000000  0.842105  0.900253\n",
       "9699    1.0     1.0  0.862069  1.000000  0.960859\n",
       "25021   0.0     0.0  0.620690  0.105263  0.888889\n",
       "6160    1.0     1.0  0.724138  0.473684  0.953283\n",
       "3055    0.0     1.0  0.689655  0.421053  0.888889\n",
       "13478   1.0     1.0  0.724138  0.368421  0.953283\n",
       "24500   0.0     1.0  0.965517  0.947368  0.887626\n",
       "21127   1.0     0.0  0.793103  0.736842  0.952020\n",
       "26383   0.0     0.0  1.000000  0.736842  0.864899\n",
       "19475   1.0     0.0  0.862069  0.894737  0.948232\n",
       "12816   0.0     1.0  0.810345  0.842105  0.856061\n",
       "24329   1.0     1.0  0.655172  0.000000  0.944444\n",
       "25925   0.0     0.0  0.827586  0.736842  0.853535\n",
       "11152   1.0     1.0  1.000000  0.947368  0.944444\n",
       "6287    0.0     1.0  0.655172  0.736842  0.849747\n",
       "16978   1.0     0.0  0.586207  1.000000  0.930556\n",
       "17964   0.0     0.0  0.724138  0.473684  0.849747\n",
       "5951    0.0     0.0  0.482759  0.210526  0.848485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr = DeterministicReranking(unprivileged_groups=[{'race': 0}], privileged_groups=[{'race': 1}])\n",
    "fair_ranking = dr.fit_predict(dataset, rec_size=20, target_prop=[0.5, 0.5], rerank_type='Constrained')\n",
    "fair_ranking.convert_to_dataframe()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems much better.\n",
    "\n",
    "To get a better idea of the level of fairness, we can quantify it using the **Infeasible Index** metric, which measures the number of indices at which the fairness requirements are violated. For a ranking of size $r$ and groups of items $g_i \\in G$ with desired proportions $p_i$ it is defined as follows:\n",
    "\n",
    "$$InfeasibleIndex_r = \\sum_{k=0}^{r} 1(\\exists\\ group\\ g_i \\in G: count_k(g_i) < \\lfloor(p_i*k)\\rfloor)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate the InfeasibleIndex using the `infeasible_index` method of the `RegressionDatasetMetric` class, first for the strictly score-based ranking, and then for the fair ranking.\n",
    "\n",
    "It returns the value of the metric, as well as positions in the ranking at which the fairness constraints are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.metrics.regression_metric import RegressionDatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RegressionDatasetMetric(dataset=unfair_ranking, unprivileged_groups=[{'race': 0}], privileged_groups=[{'race': 1}])\n",
    "m.infeasible_index(target_prop={0: 0.5, 1: 0.5}, r=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, [1, 3, 5, 7, 9, 11, 13, 15, 17])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The II for this ranking is much better!\n",
    "m_fair = RegressionDatasetMetric(dataset=fair_ranking, unprivileged_groups=[{'race': 0}], privileged_groups=[{'race': 1}])\n",
    "m_fair.infeasible_index(target_prop={0: 0.5, 1: 0.5}, r=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now quantify the loss in the quality of the ranking (how \"out of order\" the items are, based on their scores) induced by the reranking algorithm. For this we can use the **Discounted Cumulative Gain**, defined as follows:\n",
    "\n",
    "$$DCG@r = \\sum_{j=0}^{r} \\frac{score(j)}{log_2(j+1)}$$\n",
    "\n",
    "where $score(j)$ denotes the score of the item at position $j$.\n",
    "\n",
    "Setting `normalized` to `True` normalizes the metric against the DCG of top `r` elements of the full dataset by score, allowing us to compare the fair ranking to a purely score-based one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DCG of fair ranking: 0.9773523486131529\n"
     ]
    }
   ],
   "source": [
    "print(f'Normalized DCG of fair ranking: {m_fair.discounted_cum_gain(normalized=True, full_dataset=dataset, r=20)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Variations of the algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` and `fit_predict` methods of the algorithm include a `rerank_type` parameter. It refers to the different algorithms described in the original paper: **Greedy**, **Conservative**, **Relaxed** and **Constrained**. The difference between them lies in how, given a desired proportion of groups, they choose the next element in the ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting into the details, we need to formalize the properties we want our ranking to satisfy:\n",
    "- $\\forall k \\le |\\tau_r|, \\quad \\forall a \\in A: \\quad count_k(a) \\ge \\lfloor p_a*k \\rfloor$,\n",
    "- $\\forall k \\le |\\tau_r|, \\quad \\forall a \\in A: \\quad count_k(a) \\le \\lceil p_a*k \\rceil$\n",
    "\n",
    "where $|\\tau_r|$ is the size of the ranking, $A$ is the set of groups, $count_k(a)$ is the number of elements of group $a$ in first $k$ elements of the ranking, and $p_a$ is the desired proportion of elements belonging to the group $a$ in the ranking.\n",
    "\n",
    "We refer to these properties as the minimum and the maximum representation constraints, respectively.\n",
    "\n",
    "The demand for the properties to be satisfied at every $k$ comes from the observation that the position of an element in the ranking can have a significant impact on the response of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Greedy** variant works as follows:\n",
    "- If there are any groups for which the minimum representation constraint is violated (the proportion of the group in the ranking is too small), choose the element with the highest score among those groups;\n",
    "- Otherwise, choose the element with the highest score among groups that do not violate the maximum constraint (i.e. aren't overrepresented)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Conservative** and **Relaxed** variants give preference to underrepresented groups:\n",
    "- If there are any groups for which the minimum representation constraint is violated, choose the element with the highest score among those groups (analogous to Greedy)\n",
    "- Otherwise, among groups that do not violate the maximum constraint, pick the group that minimizes $\\frac{\\lceil p_a*k \\rceil}{p_a}$ if Conservative or $\\lceil\\frac{\\lceil p_a*k \\rceil}{p_a}\\rceil$ if Relaxed. From this group, choose the element with the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Constrained** variant differs significantly from both of the previous ones:\n",
    "- Starting with 0, increase the value of *k* until the minimum representation constraint is increased for at least one group. If there are more than one such groups, order them according to the descending score of their highest-scoring candidates not yet in the ranking.\n",
    "- For each group in the list above:\n",
    "    1. Insert the next candidate from the group to the next empty index in the ranking\n",
    "    2. Swap the candidate towards earlier indices until:\n",
    "        - Either the score of the candidate in the earlier index is larger, or,\n",
    "        - Swapping will violate the minimum condition for the group of the candidate in the earlier index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental results (see reference) show that all algorithms exhibit similar performance in terms of both list utility and fairness. The Greedy algorithm generates ranked lists with higher utility, but doesn't strictly adhere to the fairness constraints; among the rest, Constrained shows the best utility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
